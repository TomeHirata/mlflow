import { APILink } from "@site/src/components/APILink";
import Tabs from "@theme/Tabs";
import TabItem from "@theme/TabItem";

# MLflow Prompt Data Model

MLflow **Prompt Registry** provides a structured approach to managing prompt templates for GenAI applications through versioned, reusable prompt entities. The Prompt data model enables systematic prompt engineering, version control, and deployment management across your organization.

## Overview

The MLflow Prompt data model centers around the **Prompt** entity, which represents a versioned template with comprehensive metadata and lifecycle management capabilities.

```mermaid
graph TD
    subgraph PROMPT[📝 MLflow Prompt Entity]
        direction TB
        TITLE[🎯 Versioned Template Container]

        subgraph CORE[📊 Core Properties]
            NAME[📛 Name]
            TEMPLATE[📄 Template Text]
            VERSION[🔢 Version Number]
        end

        subgraph METADATA[📋 Metadata]
            COMMIT[💬 Commit Message]
            TAGS[🔖 Version Tags]
            DESC[📝 Description]
        end

        subgraph MANAGEMENT[⚙️ Management]
            ALIASES[🎯 Aliases]
            TIMESTAMP[⏰ Creation Time]
            LIFECYCLE[🔄 Lifecycle State]
        end

        TITLE -.-> CORE
        TITLE -.-> METADATA
        TITLE -.-> MANAGEMENT
    end

    classDef promptStyle fill:#e8f5e8,stroke:#2e7d32,stroke-width:3px,color:#000
    classDef coreStyle fill:#e3f2fd,stroke:#0277bd,stroke-width:2px,color:#000
    classDef metaStyle fill:#fff3e0,stroke:#ef6c00,stroke-width:2px,color:#000
    classDef mgmtStyle fill:#f3e5f5,stroke:#7b1fa2,stroke-width:2px,color:#000
    classDef titleStyle fill:#f5f5f5,stroke:#424242,stroke-width:2px,color:#000

    class PROMPT promptStyle
    class CORE,NAME,TEMPLATE,VERSION coreStyle
    class METADATA,COMMIT,TAGS,DESC metaStyle
    class MANAGEMENT,ALIASES,TIMESTAMP,LIFECYCLE mgmtStyle
    class TITLE titleStyle
```

## Prompt as a Versioned Entity

### Centralized Template Management

The Prompt entity provides a single source of truth for template definitions, enabling consistent reuse across multiple applications and teams while maintaining version history and change tracking.

### Git-Inspired Versioning

Prompt versioning follows Git-like principles with sequential version numbers, commit messages describing changes, and immutable versions that ensure reproducibility and rollback capabilities.

### Dynamic Variable Support

Templates support variable interpolation using double-brace syntax (`{{variable}}`), enabling flexible content generation while maintaining template structure and reusability.

## Prompt Core Properties

### Identity and Content

Every Prompt has fundamental identification and content properties:

```mermaid
graph TB
    PROMPT[📝 Prompt Entity]

    subgraph IDENTITY[📛 Identity Properties]
        NAME[Name: Unique identifier]
        NAMESPACE[Namespace: Organization scope]
        URI[URI: prompts:/name/version]
    end

    subgraph CONTENT[📄 Content Properties]
        TEMPLATE[Template: Text with variables]
        VARIABLES[Variables: Extracted template parameters]
        FORMAT[Format: Double-brace syntax]
    end

    subgraph VERSION[🔢 Version Properties]
        NUMBER[Version Number: Sequential]
        IMMUTABLE[Immutability: Read-only after creation]
        HISTORY[History: Complete version chain]
    end

    PROMPT --> IDENTITY
    PROMPT --> CONTENT
    PROMPT --> VERSION

    classDef promptStyle fill:#e8f5e8,stroke:#2e7d32,stroke-width:3px,color:#000
    classDef identityStyle fill:#e3f2fd,stroke:#0277bd,stroke-width:2px,color:#000
    classDef contentStyle fill:#fff3e0,stroke:#ef6c00,stroke-width:2px,color:#000
    classDef versionStyle fill:#f3e5f5,stroke:#7b1fa2,stroke-width:2px,color:#000

    class PROMPT promptStyle
    class IDENTITY,NAME,NAMESPACE,URI identityStyle
    class CONTENT,TEMPLATE,VARIABLES,FORMAT contentStyle
    class VERSION,NUMBER,IMMUTABLE,HISTORY versionStyle
```

### Template Structure

Prompt templates support sophisticated variable interpolation and multiple formats:

<Tabs>
<TabItem value="text" label="Text Templates" default>

Text templates use string-based content with variable interpolation:

```python
# Example text template with variables
template = """
You are an expert {{ role }}. Analyze the following {{ content_type }} and provide {{ num_points }} key insights.

Content: {{ content }}

Requirements:
- Focus on {{ focus_area }}
- Use {{ tone }} tone
- Limit response to {{ max_length }} words
"""

# Variables automatically extracted: role, content_type, num_points, content, focus_area, tone, max_length
```

</TabItem>
<TabItem value="chat" label="Chat Templates">

Chat templates use structured message arrays for conversational AI:

```python
# Example chat template with multiple messages
chat_template = [
    {"role": "system", "content": "You are a helpful {{ style }} assistant."},
    {"role": "user", "content": "{{ question }}"},
    {"role": "assistant", "content": "I'll help you with that."},
    {"role": "user", "content": "Can you provide more details about {{ topic }}?"},
]

# Variables automatically extracted: style, question, topic
```

</TabItem>
</Tabs>

### Tags

Tags store version-specific metadata and prompt type information:

```python
# Register prompt with comprehensive tags
prompt = mlflow.genai.register_prompt(
    name="content-analyzer",
    template=template,
    commit_message="Added tone and length controls",
    tags={
        "author": "ai-team@company.com",
        "purpose": "Content analysis with customizable output",
        "model": "gpt-4",
        "performance_score": "0.92",
        "review_status": "approved",
    },
)
```

### Response Formats

Response formats define expected output structures for structured generation:

```python
from pydantic import BaseModel


class AnalysisResponse(BaseModel):
    summary: str
    key_points: list[str]
    confidence_score: float


# Register prompt with response format
prompt = mlflow.genai.register_prompt(
    name="content-analyzer",
    template=template,
    response_format=AnalysisResponse,
    commit_message="Added structured response format",
)

# Or use dictionary format
prompt = mlflow.genai.register_prompt(
    name="qa-prompt",
    template="Answer: {{ question }}",
    response_format={
        "type": "object",
        "properties": {
            "answer": {"type": "string"},
            "confidence": {"type": "number"},
            "sources": {"type": "array", "items": {"type": "string"}},
        },
    },
)
```

## Prompt Lifecycle Management

### Creation and Versioning

Prompts follow a systematic lifecycle with clear creation and update patterns:

```mermaid
graph TB
    CREATE[📝 Create Initial Prompt]

    subgraph DEVELOPMENT[🔧 Development Phase]
        ITERATE[🔄 Iterative Updates]
        TEST[🧪 Testing Versions]
        REFINE[✨ Refinement]
    end

    subgraph DEPLOYMENT[🚀 Deployment Phase]
        ALIAS[🎯 Alias Assignment]
        PRODUCTION[🏭 Production Use]
        MONITOR[📊 Performance Monitoring]
    end

    subgraph MAINTENANCE[🛠️ Maintenance Phase]
        UPDATE[🔄 Version Updates]
        ROLLBACK[↩️ Rollback Capability]
        ARCHIVE[📦 Archive Management]
    end

    CREATE --> DEVELOPMENT
    DEVELOPMENT --> DEPLOYMENT
    DEPLOYMENT --> MAINTENANCE
    MAINTENANCE --> DEVELOPMENT

    classDef createStyle fill:#e8f5e8,stroke:#2e7d32,stroke-width:3px,color:#000
    classDef devStyle fill:#e3f2fd,stroke:#0277bd,stroke-width:2px,color:#000
    classDef deployStyle fill:#fff3e0,stroke:#ef6c00,stroke-width:2px,color:#000
    classDef maintainStyle fill:#f3e5f5,stroke:#7b1fa2,stroke-width:2px,color:#000

    class CREATE createStyle
    class DEVELOPMENT,ITERATE,TEST,REFINE devStyle
    class DEPLOYMENT,ALIAS,PRODUCTION,MONITOR deployStyle
    class MAINTENANCE,UPDATE,ROLLBACK,ARCHIVE maintainStyle
```

### Alias Management

Aliases provide mutable references to prompt versions for flexible deployment:

```mermaid
graph TB
    PROMPT[📝 Prompt: summarization-prompt]

    subgraph VERSIONS[🔢 Available Versions]
        V1[Version 1: Initial]
        V2[Version 2: Improved]
        V3[Version 3: Enhanced]
        V4[Version 4: Latest]
    end

    subgraph ALIASES[🎯 Active Aliases]
        PROD[production → Version 2]
        STAGING[staging → Version 4]
        BETA[beta → Version 3]
    end

    PROMPT --> VERSIONS
    PROMPT --> ALIASES

    classDef promptStyle fill:#e8f5e8,stroke:#2e7d32,stroke-width:3px,color:#000
    classDef versionStyle fill:#e3f2fd,stroke:#0277bd,stroke-width:2px,color:#000
    classDef aliasStyle fill:#fff3e0,stroke:#ef6c00,stroke-width:2px,color:#000

    class PROMPT promptStyle
    class VERSIONS,V1,V2,V3,V4 versionStyle
    class ALIASES,PROD,STAGING,BETA aliasStyle
```

## Prompt Usage Patterns

### Loading and Formatting

Prompts are loaded and used through systematic patterns with support for different template types:

<Tabs>
<TabItem value="text-prompts" label="Text Prompts" default>

Text prompts use string-based templates with variable interpolation:

```python
# Load specific version
prompt = mlflow.genai.load_prompt("prompts:/summarization-prompt/2")

# Check prompt properties
print(f"Is text prompt: {prompt.is_text_prompt}")
print(f"Response format: {prompt.response_format}")

# Format with variables
formatted_text = prompt.format(
    num_sentences=3, content="Your content here...", tone="professional"
)
```

</TabItem>
<TabItem value="chat-prompts" label="Chat Prompts">

Chat prompts use structured message arrays for conversational AI:

```python
# Load specific version of chat prompt
chat_prompt = mlflow.genai.load_prompt("prompts:/assistant-prompt/2")

# Check prompt properties
print(f"Is text prompt: {chat_prompt.is_text_prompt}")
print(f"Response format: {chat_prompt.response_format}")

# Format with variables
formatted_messages = chat_prompt.format(
    style="friendly",
    domain="machine learning",
    question="What is MLflow?",
    specific_aspect="its tracking capabilities",
)
```

</TabItem>
<TabItem value="alias-loading" label="Alias Loading">

Load prompts via aliases for deployment flexibility:

```python
# Load via alias for deployment flexibility
prompt = mlflow.genai.load_prompt("prompts:/summarization-prompt@production")

# Same formatting interface works for both types
if prompt.is_text_prompt:
    formatted = prompt.format(num_sentences=3, content="Your content here...")
else:
    formatted = prompt.format(style="professional", question="Your question here...")
```

  </TabItem>
  <TabItem value="search" label="Discovery and Search">
    ```python
    # Search prompts by criteria
    prompts = mlflow.genai.search_prompts(filter_string="name LIKE 'my_prompt%'")

    # Load discovered prompt
    prompt = mlflow.genai.load_prompt(f"prompts:/{prompts[0].name}/{prompts[0].version}")
    ```

  </TabItem>
</Tabs>

### Framework Integration

Prompts integrate seamlessly with popular GenAI frameworks:

```python
from langchain.prompts import PromptTemplate
from langchain_core.prompts import ChatPromptTemplate

# Load text prompt from MLflow and convert format
text_prompt = mlflow.genai.load_prompt("prompts:/qa-prompt/1")
langchain_text_prompt = PromptTemplate.from_template(
    text_prompt.to_single_brace_format()
)

# Load chat prompt from MLflow
chat_prompt = mlflow.genai.load_prompt("prompts:/assistant-prompt/1")
formatted_messages = chat_prompt.format(style="friendly", question="What is MLflow?")
langchain_chat_prompt = ChatPromptTemplate.from_messages(formatted_messages)
```

</TabItem>
<TabItem value="openai" label="OpenAI">

OpenAI integration works with both prompt types:

```python
import openai

client = openai.OpenAI()

# Use text prompt
text_prompt = mlflow.genai.load_prompt("prompts:/qa-prompt/1")
text_response = client.chat.completions.create(
    messages=[
        {"role": "user", "content": text_prompt.format(question="What is MLflow?")}
    ],
    model="gpt-4",
)

# Use chat prompt directly
chat_prompt = mlflow.genai.load_prompt("prompts:/assistant-prompt/1")
formatted_messages = chat_prompt.format(style="friendly", question="What is MLflow?")
chat_response = client.chat.completions.create(
    messages=formatted_messages,
    model="gpt-4",
)
```

</TabItem>
</Tabs>

## Prompt Comparison and Evolution

### Version Comparison

MLflow provides built-in comparison capabilities for prompt evolution:

```mermaid
graph TB
    COMPARISON[📊 Prompt Version Comparison]

    subgraph ANALYSIS[🔍 Comparison Analysis]
        DIFF[Text Diff: Line-by-line changes]
        VARIABLES[Variable Changes: Added/removed parameters]
        METADATA[Metadata Evolution: Context changes]
    end

    subgraph METRICS[📈 Performance Metrics]
        QUALITY[Quality Scores: Performance comparison]
        USAGE[Usage Patterns: Adoption metrics]
        FEEDBACK[User Feedback: Qualitative assessment]
    end

    subgraph DECISION[🎯 Decision Support]
        PROMOTION[Version Promotion: Alias updates]
        ROLLBACK[Rollback Planning: Safety measures]
        ADOPTION[Adoption Strategy: Deployment planning]
    end

    COMPARISON --> ANALYSIS
    COMPARISON --> METRICS
    COMPARISON --> DECISION

    classDef compStyle fill:#e8f5e8,stroke:#2e7d32,stroke-width:3px,color:#000
    classDef analysisStyle fill:#e3f2fd,stroke:#0277bd,stroke-width:2px,color:#000
    classDef metricsStyle fill:#fff3e0,stroke:#ef6c00,stroke-width:2px,color:#000
    classDef decisionStyle fill:#f3e5f5,stroke:#7b1fa2,stroke-width:2px,color:#000

    class COMPARISON compStyle
    class ANALYSIS,DIFF,VARIABLES,METADATA analysisStyle
    class METRICS,QUALITY,USAGE,FEEDBACK metricsStyle
    class DECISION,PROMOTION,ROLLBACK,ADOPTION decisionStyle
```

## Benefits of Prompt-Centric Organization

### Centralized Management

The Prompt Registry provides **unified template storage** that eliminates scattered prompt definitions across applications, **version control** that maintains complete change history with rollback capabilities, **collaborative development** that enables team sharing and review processes, and **consistency enforcement** that ensures standardized prompt usage across projects.

### Development Efficiency

Prompt entities enable **reusability** through shared templates across multiple applications, **systematic testing** via version comparison and performance tracking, **deployment flexibility** using aliases for environment-specific deployments, and **framework agnostic** integration with any GenAI library or service.

### Quality Assurance

The structured approach supports **change tracking** with detailed commit messages and metadata, **performance monitoring** through integrated metrics and feedback, **collaborative review** via shared access and version comparison, and **rollback safety** through immutable versions and alias management.

## Prompt Management Best Practices

### Naming and Organization

**Descriptive naming** should use clear, consistent names that reflect prompt purpose and domain. **Logical grouping** can leverage tags for functional and organizational categorization. **Version strategy** needs meaningful commit messages that document changes and improvements. **Alias strategy** should establish clear alias purposes like production, staging, and development.

### Template Design

**Variable design** should use descriptive variable names that clearly indicate expected content. **Documentation** must include inline comments and comprehensive metadata for template usage. **Modularity** can break complex prompts into reusable components where possible. **Testing** requires systematic validation across different input scenarios and edge cases.

### Lifecycle Management

**Version planning** should establish clear criteria for creating new versions versus minor updates. **Performance tracking** needs monitoring of prompt effectiveness and user satisfaction metrics. **Deployment coordination** requires synchronized alias updates across environments. **Archive management** should establish policies for managing old versions and cleanup procedures.

## Getting Started with Prompt Registry

Creating and managing prompts involves several key steps:

**Register your first prompt** using <APILink fn="mlflow.genai.register_prompt" /> with comprehensive metadata and clear commit messages. **Establish version workflow** by creating new versions for significant changes and using descriptive commit messages. **Implement alias strategy** by setting up aliases for different environments and use cases. **Integrate with applications** by loading prompts via <APILink fn="mlflow.genai.load_prompt" /> and formatting with dynamic variables.

```python
# Complete workflow example
import mlflow
from pydantic import BaseModel


class SupportResponse(BaseModel):
    response: str
    confidence: float
    suggested_actions: list[str]


# 1. Register initial text prompt
text_prompt = mlflow.genai.register_prompt(
    name="customer-support",
    template="You are a helpful {{ role }}. Please {{ action }} for: {{ query }}",
    response_format=SupportResponse,
    commit_message="Initial customer support template",
    tags={"domain": "support", "language": "en"},
)

# 2. Register chat prompt
chat_prompt = mlflow.genai.register_prompt(
    name="assistant-chat",
    template=[
        {"role": "system", "content": "You are a {{ style }} assistant."},
        {"role": "user", "content": "{{ question }}"},
    ],
    response_format={"type": "object", "properties": {"response": {"type": "string"}}},
    commit_message="Initial chat assistant template",
    tags={"domain": "assistant", "language": "en"},
)

# 3. Create production aliases
mlflow.set_prompt_alias("customer-support", "production", 1)
mlflow.set_prompt_alias("assistant-chat", "production", 1)

# 4. Load and use in application
production_text_prompt = mlflow.genai.load_prompt(
    "prompts:/customer-support@production"
)
formatted_text = production_text_prompt.format(
    role="customer service agent",
    action="provide assistance",
    query="How do I reset my password?",
)

production_chat_prompt = mlflow.genai.load_prompt("prompts:/assistant-chat@production")
formatted_messages = production_chat_prompt.format(
    style="friendly",
    question="What is MLflow?",
)
```

## Next Steps

**[Prompt Management Guide](/genai/prompt-version-mgmt/prompt-registry/)** provides comprehensive guidance on creating, versioning, and managing prompts effectively. **[MLflow UI Navigation](/genai/tracing/observe-with-traces/ui)** helps you master the interface for exploring and managing prompts.

MLflow Prompt Registry provides the essential framework for systematic prompt engineering, enabling teams to build, version, and deploy high-quality prompt templates with confidence and collaboration.
